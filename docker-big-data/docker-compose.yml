version: "3"

services:
  # hadoop namenode
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop-hive.env
    ports:
      - "50070:50070"

  # hadoop datanode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"

  # resource manager
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
    container_name: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075"
    env_file:
      - ./hadoop-hive.env
    ports:
      - 8088:8088

  # node manager
  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8
    container_name: nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 resourcemanager:8088"
    env_file:
      - ./hadoop-hive.env
    ports:
      - 8042:8042

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop2.7.4-java8
    container_name: historyserver
    volumes:
      - historyserver:/hadoop/yarn/timeline
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 resourcemanager:8088"
    env_file:
      - ./hadoop-hive.env
    ports:
      - 8188:8188

  # hive server
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10010:10000"
    
  # hive metastore
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
      
  # hive metastore postgresql
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    ports:
      - "7070:8080"

  # spark master node
  spark-master:
    image: bde2020/spark-master:2.1.0-hadoop2.8-hive-java8
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./hadoop-hive.env
  
  # spark worker node
  spark-worker:
    image: bde2020/spark-worker:2.1.0-hadoop2.8-hive-java8
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - 8081:8081
    env_file:
      - ./hadoop-hive.env
  
  spark-notebook:
    image: bde2020/spark-notebook:2.1.0-hadoop2.8-hive
    container_name: spark-notebook
    env_file:
      - ./hadoop-hive.env
    ports:
      - 9001:9001
  
  hue:
    image: bde2020/hdfs-filebrowser:3.11
    ports:
      - 9099:8088
    environment:
      - NAMENODE_HOST=namenode

  # zookeeper
  # zookeeper:
  #       image: wurstmeister/zookeeper
  #       container_name: zookeeper 
  #       restart: always
  #       environment:
  #         ZOO_MY_ID: 1
  #         ZOO_SERVERS: server.1=0.0.0.0:2888:3888 
  #       ports:
  #           - 2181:2181
  zookeeper:
    image: zookeeper:3.4.10
    container_name: zookeeper
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888
    ports:
      - 2181:2181

  # kafka 1
  kafka1:
      image: wurstmeister/kafka
      restart: always
      depends_on:
          - zookeeper
      ports:
          - 9093:9093
      environment:
          KAFKA_ADVERTISED_HOST_NAME: kafka1
          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181/kafka
          KAFKA_LISTENERS: PLAINTEXT://:9093
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.31.41.139:9093
          KAFKA_BROKER_ID: 1
          KAFKA_CREATE_TOPICS: "event_second,event_hour"
      volumes:
          - /var/run/docker.sock:/var/run/docker.sock

  # kafka 2
  kafka2:
      image: wurstmeister/kafka
      restart: always
      depends_on:
          - zookeeper
      ports:
          - 9094:9094
      environment:
          KAFKA_ADVERTISED_HOST_NAME: kafka2
          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181/kafka
          KAFKA_LISTENERS: PLAINTEXT://:9094
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.31.41.139:9094
          KAFKA_BROKER_ID: 2
      volumes:
          - /var/run/docker.sock:/var/run/docker.sock

  # kafka 3
  kafka3:
      image: wurstmeister/kafka
      restart: always
      depends_on:
          - zookeeper
      ports:
          - 9095:9095
      environment:
          KAFKA_ADVERTISED_HOST_NAME: kafka3
          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181/kafka
          KAFKA_LISTENERS: PLAINTEXT://:9095
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.31.41.139:9095
          KAFKA_BROKER_ID: 3
      volumes:
          - /var/run/docker.sock:/var/run/docker.sock

  # hbase master
  hbase-master:
    image: bde2020/hbase-master:1.0.0-hbase1.2.6
    # build: .
    container_name: hbase-master
    hostname: hbase-master
    env_file:
      - ./hbase-distributed-local.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 zookeeper:2181"
    ports:
      - 16010:16010
      - 9090:9090

  hbase-region:
    image: bde2020/hbase-regionserver:1.0.0-hbase1.2.6
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    env_file:
      - ./hbase-distributed-local.env
    environment:
      HBASE_CONF_hbase_regionserver_hostname: hbase-region
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 zookeeper:2181 hbase-master:16010"
    ports:
      - 16030:16030

volumes:
  namenode:
  datanode:
  historyserver: